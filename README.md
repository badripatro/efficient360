
# Efficient360: Efficient Vision Transformer
The efficient 360 framework is a collection of transformer models in various dimensions.

## Various Dimensions of Efficient360
![Efficient 360](images/Transformer_ven_diagram_E360_v3.png) 

## Vision Transformer Models and their comparisons.
![model](images/transformer_models.png) 

## Inference on Deit-based transformer Model and its Grad-CAM Explanation
![Deit Model Inference](images/transformer_inference.png) 

## Architectural performance of Various Transformer Models
![Model Performance](images/model_performance.png) 

## Architectural performance of Various SOTA Transformer Models
![All Model Performance](images/all_model_performance_acc.png)


## State of the Art results of various vision transformer models on ImageNet-1K dataset with Image size 224 x 224.
![SOTA224](images/ImageNet1K_224.png) 

## State of the Art results of various vision transformer models on ImageNet-1K dataset with different Image sizes.
![SOTA](images/ImageNet1K_384.png) 


## State of the Art results of various vision transformer models on ImageNet-22K dataset with different Image sizes.
![SOTA1](images/ImageNet22K.png) 


## State of the Art results of various Spectral Vision Transformer models on ImageNet-1K dataset with different Image sizes.
![SOTA2](images/spectral_net.png) 


 ## Transfer Learning results of various datasets like CIFAR10, CIFAR100, Pet, Flower, and Cars datasets, The models are  pre-trained on ImageNet-1K and ImageNet-22K datasets.
![SOTA3](images/transfer_learning.png) 

 ## Long Range Arena (LRA) Benchmark Datasets  and its corresponding tasks.
![SOTA4](images/lra.png)
